{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasetX.pkl  dishCodes2.npy  wordDict2.pkl  wordList2.pkl\r\n",
      "datasetY.pkl  dishCodes.npy   wordDict.pkl   wordList.pkl\r\n"
     ]
    }
   ],
   "source": [
    "PATH = Path('../../data/menu')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "rawData = 'Dish.csv'\n",
    "!ls '../../data/menu/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRaw = pd.read_csv((PATH/rawData).open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenIdx(rows):\n",
    "    freqs = Counter(wd for name in rows for wd in name.split(' ') )\n",
    "    itos = [key for key, count in freqs.most_common()]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda:3, {v:k for k,v in enumerate(itos)})\n",
    "    strCodes = [([stoi[i] for i in name.split(' ')]) for name in rows ]\n",
    "    strCodes = np.array(strCodes)\n",
    "    np.save(TMP_PATH/'dishCodes.npy', strCodes)\n",
    "    pickle.dump(itos, open(TMP_PATH/'wordList.pkl','wb'))\n",
    "    pickle.dump(dict(stoi), open(TMP_PATH/'wordDict.pkl','wb'))\n",
    "    # freqFreq = Counter(count for key, count in freqs.most_common())\n",
    "    # freqFreq.most_common()\n",
    "    return strCodes, stoi, itos\n",
    "# strCodes, stoi, itos = getTokenIdx(dfRaw.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTokenIdx():\n",
    "    strCodes = np.load(TMP_PATH/'dishCodes.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/'wordList.pkl','rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, pickle.load(open(TMP_PATH/'wordDict.pkl','rb')))\n",
    "    return strCodes, stoi, itos\n",
    "strCodes, stoi, itos = loadTokenIdx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147016, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dict2Vec(w2vDict):\n",
    "    return np.random.rand(len(w2vDict), 30)\n",
    "dict2Vec(stoi).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostLength = int(np.percentile([len(o) for o in strCodes], 98))\n",
    "mostLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"1234567\"\n",
    "np.random.randint(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9111\n",
      "Soup, Tomato, with Macaroni|Roast Saddle of Mutton, Red Currant Jelly, Cabbage, Potatoes and Rolls 9/-|GRANATINA (Mixed Flavors)|Frankfurters with Beans|Fresh Crab Legs|\n"
     ]
    }
   ],
   "source": [
    "def genDataSet(strCodes, size, mostLength, genLength):\n",
    "    Xs, Ys = [], []\n",
    "    for i in range(size):\n",
    "        randIdxes = random.sample(range(len(strCodes)), genLength)\n",
    "        X, Y = [], []\n",
    "        for randIdx in randIdxes:\n",
    "            if len(strCodes[randIdx]) > mostLength:\n",
    "                break\n",
    "            X += strCodes[randIdx]\n",
    "            Y += [0]*(len(strCodes[randIdx])-1)+[1]\n",
    "        if np.sum(Y) == genLength:\n",
    "            Xs.append(X)\n",
    "            Ys.append(Y)\n",
    "    pickle.dump(Xs, open(TMP_PATH/'datasetX.pkl','wb'))\n",
    "    pickle.dump(Ys, open(TMP_PATH/'datasetY.pkl','wb'))\n",
    "    return Xs, Ys\n",
    "def loadDataSet():\n",
    "    Xs = pickle.load(open(TMP_PATH/'datasetX.pkl','rb'))\n",
    "    Ys = pickle.load(open(TMP_PATH/'datasetY.pkl','rb'))\n",
    "    return Xs, Ys\n",
    "\n",
    "# Xs, Ys = genDataSet(strCodes, 10000, mostLength, 5)\n",
    "Xs, Ys = loadDataSet()\n",
    "def interpret(Xs, Ys):\n",
    "    XsOg = \"\"\n",
    "    pick = np.random.randint(len(Xs))\n",
    "    for i, x in enumerate(Xs[pick]):\n",
    "        XsOg = XsOg + itos[x] + [' ', '|'][Ys[pick][i] == 1]\n",
    "    print(len(Xs))\n",
    "    print(XsOg)\n",
    "interpret(Xs, Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8202\n",
      "WIENER SCHNITZEL SPAETZLES, ONE VEG.|Canned Plums|De Lossy-Holden, Brut, '92 Champagne|Goose Liver au Naturel in its Jelly|Whiskey, Old Tom Pepper|\n",
      "909\n",
      "BorjumÃ¡j piritva burg|Chopped Beef Steak, Smothered Onions, Sliced Tomato|OUR SPECIAL GROUND HAMBURGER SANDWICH - Very Delicious|Pouding Chambord|Cold Fresh Salmon, Garni, Mayonnaise|\n"
     ]
    }
   ],
   "source": [
    "def splitDataset(Xs, Ys):\n",
    "    np.random.seed(9)\n",
    "    Xs, Ys = np.array(Xs), np.array(Ys)\n",
    "    isTrainIds = np.random.rand(len(Xs))>0.1\n",
    "    trnXs, trnYs = Xs[isTrainIds], Ys[isTrainIds]\n",
    "    valXs, valYs = Xs[~isTrainIds], Ys[~isTrainIds]\n",
    "    pickle.dump(trnXs, open(TMP_PATH/'trnXs.pkl','wb'))\n",
    "    pickle.dump(trnYs, open(TMP_PATH/'trnYs.pkl','wb'))\n",
    "    pickle.dump(valXs, open(TMP_PATH/'valXs.pkl','wb'))\n",
    "    pickle.dump(valYs, open(TMP_PATH/'valYs.pkl','wb'))\n",
    "    return trnXs, trnYs, valXs, valYs\n",
    "\n",
    "def loadSplitDataset():\n",
    "    trnXs = pickle.load(open(TMP_PATH/'trnXs.pkl','rb'))\n",
    "    trnYs = pickle.load(open(TMP_PATH/'trnYs.pkl','rb'))\n",
    "    valXs = pickle.load(open(TMP_PATH/'valXs.pkl','rb'))\n",
    "    valYs = pickle.load(open(TMP_PATH/'valYs.pkl','rb'))\n",
    "    return trnXs, trnYs, valXs, valYs\n",
    "\n",
    "# trnXs, trnYs, valXs, valYs = splitDataset(Xs, Ys)\n",
    "trnXs, trnYs, valXs, valYs = loadSplitDataset()\n",
    "interpret(trnXs, trnYs)\n",
    "interpret(valXs, valYs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], self.y[idx])\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnDS = Seq2SeqDataset(trnXs, trnYs)\n",
    "valDS = Seq2SeqDataset(valXs, valYs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=125\n",
    "trnSamp = SortishSampler(trnXs, key=lambda x: len(trnXs), bs=bs)\n",
    "valSamp = SortSampler(valXs, key=lambda x:len(valXs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnDL = DataLoader(trnDS, bs,transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trnSamp)\n",
    "valDL = DataLoader(valDS, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=valSamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
